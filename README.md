# ğŸŒ Climate Intelligence Platform for Extreme Weather Prediction

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-7.5-red.svg)](https://kafka.apache.org)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5.1-orange.svg)](https://spark.apache.org)
[![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED.svg)](https://docker.com)
[![Groq](https://img.shields.io/badge/Groq%20LLM-Gen%20AI-green.svg)](https://groq.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> A production-grade, end-to-end climate intelligence platform that ingests real-time weather data from OpenWeatherMap, processes it through a medallion data lake using Apache Spark, predicts extreme weather events using XGBoost & LSTM, and provides Gen AI-powered natural language insights via Groq LLM â€” orchestrated with Apache Airflow and containerized with Docker.

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Getting Started](#-getting-started)
- [Pipeline Deep Dive](#-pipeline-deep-dive)
- [ML Models](#-ml-models)
- [Gen AI Integration](#-gen-ai-integration)
- [API Documentation](#-api-documentation)
- [Implementation Roadmap](#-implementation-roadmap)
- [License](#-license)

---

## ğŸ¯ Overview

### The Problem
Extreme weather events (heatwaves, floods, hurricanes, storms) are increasing in frequency and severity. Early prediction can save lives, reduce economic damage, and help communities prepare. Current systems often lack real-time processing, explainability, and accessible interfaces for non-technical users.

### The Solution
This platform combines **real-time data engineering**, **machine learning**, and **generative AI** to:
- Ingest live weather streams from 20 US cities via Apache Kafka with Avro schema validation
- Process data using Apache Spark (batch + streaming) through a Medallion Architecture
- Predict extreme weather events using an ensemble of XGBoost + LSTM models
- Generate human-readable weather intelligence reports using Groq LLM (Llama 3.1)
- Allow users to query climate data in natural language via a RAG-powered chatbot
- Orchestrate the entire pipeline with Apache Airflow

### Who Is This For?
- Emergency response agencies needing early warning systems
- Insurance companies assessing climate risk
- Researchers studying extreme weather patterns
- City planners building climate-resilient infrastructure

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA SOURCES                                     â”‚
â”‚          OpenWeatherMap API (20 US Cities, Real-Time)                     â”‚
â”‚  New York â”‚ LA â”‚ Chicago â”‚ Houston â”‚ Phoenix â”‚ Miami â”‚ Seattle â”‚ ...     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 INGESTION LAYER (Real-Time Streaming)                     â”‚
â”‚                                                                           â”‚
â”‚   Python Kafka Producer (Avro Serialization)                             â”‚
â”‚     â””â”€â”€â†’ Apache Kafka Broker                                             â”‚
â”‚            â”œâ”€â”€ Topic: raw-weather-data (3 partitions)                    â”‚
â”‚            â”œâ”€â”€ Topic: weather-alerts (2 partitions)                      â”‚
â”‚            â””â”€â”€ Topic: weather-events                                     â”‚
â”‚                                                                           â”‚
â”‚   Confluent Schema Registry (Avro) â”€â”€ Data contract enforcement          â”‚
â”‚   Kafka UI (http://localhost:8888) â”€â”€ Visual topic monitoring            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROCESSING LAYER (Batch + Stream)                            â”‚
â”‚                                                                           â”‚
â”‚   Spark Structured Streaming (with fastavro deserialization)             â”‚
â”‚     â””â”€â”€ Kafka (Avro) â†’ Bronze Layer (real-time, 30s trigger)            â”‚
â”‚                                                                           â”‚
â”‚   Spark Batch Jobs (Medallion Architecture)                              â”‚
â”‚     â”œâ”€â”€ Bronze â†’ Silver : Deduplication, null handling, validation       â”‚
â”‚     â”œâ”€â”€ Silver â†’ Gold   : Heat index, wind chill, anomaly scores,       â”‚
â”‚     â”‚                     extreme weather flags, time features (49 cols) â”‚
â”‚     â””â”€â”€ Gold  â†’ PostgreSQL: Star schema dimensional warehouse            â”‚
â”‚                                                                           â”‚
â”‚   Apache Airflow â”€â”€ DAG orchestration (http://localhost:8085)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       STORAGE LAYER                                       â”‚
â”‚                                                                           â”‚
â”‚   Local Data Lake (Parquet, Medallion Architecture)                      â”‚
â”‚     â”œâ”€â”€ data/bronze/  â†’ Raw Parquet (as received from Kafka)             â”‚
â”‚     â”œâ”€â”€ data/silver/  â†’ Cleaned, validated, deduplicated                 â”‚
â”‚     â””â”€â”€ data/gold/    â†’ 49 features, ML-ready                           â”‚
â”‚                                                                           â”‚
â”‚   PostgreSQL Data Warehouse (Star Schema)                                â”‚
â”‚     â”œâ”€â”€ Fact: fact_weather_readings (660+ records)                       â”‚
â”‚     â”œâ”€â”€ Dim:  dim_location (20 cities with regions)                      â”‚
â”‚     â”œâ”€â”€ Dim:  dim_time (hourly for 2 years)                              â”‚
â”‚     â””â”€â”€ Dim:  dim_weather_type (15 weather conditions)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ML / AI LAYER                                      â”‚
â”‚                                                                           â”‚
â”‚   XGBoost Classifier                                                     â”‚
â”‚     â”œâ”€â”€ Extreme weather classification (F1: 1.0)                         â”‚
â”‚     â”œâ”€â”€ SHAP explainability (feature importance plots)                   â”‚
â”‚     â””â”€â”€ Optuna hyperparameter tuning (50 trials)                         â”‚
â”‚                                                                           â”‚
â”‚   PyTorch LSTM                                                           â”‚
â”‚     â”œâ”€â”€ Temperature time-series forecasting (MAE: 0.039)                 â”‚
â”‚     â”œâ”€â”€ 7-step sequence window, 2-layer architecture                     â”‚
â”‚     â””â”€â”€ Training/validation loss tracking                                â”‚
â”‚                                                                           â”‚
â”‚   MLflow (http://localhost:5555)                                         â”‚
â”‚     â”œâ”€â”€ Experiment tracking (parameters, metrics, artifacts)             â”‚
â”‚     â”œâ”€â”€ Model versioning & comparison                                    â”‚
â”‚     â””â”€â”€ SHAP plots, confusion matrix, loss curves logged                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GEN AI LAYER (Groq LLM - Llama 3.1)                â”‚
â”‚                                                                           â”‚
â”‚   Weather Report Generator                                               â”‚
â”‚     â””â”€â”€ ML predictions â†’ Groq LLM â†’ Natural language reports            â”‚
â”‚                                                                           â”‚
â”‚   Anomaly Explanation Engine                                             â”‚
â”‚     â””â”€â”€ High anomaly scores â†’ LLM explains WHY in plain English         â”‚
â”‚                                                                           â”‚
â”‚   RAG Climate Chatbot (ChromaDB + Groq)                                  â”‚
â”‚     â””â”€â”€ User question â†’ Vector search â†’ LLM generates grounded answer   â”‚
â”‚                                                                           â”‚
â”‚   Text-to-SQL Engine                                                     â”‚
â”‚     â””â”€â”€ Natural language â†’ SQL â†’ PostgreSQL â†’ Natural language answer    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies | Purpose |
|----------|-------------|---------|
| **Data Ingestion** | Apache Kafka, Confluent Schema Registry (Avro), Kafka UI | Real-time streaming with schema validation |
| **Stream Processing** | Spark Structured Streaming, fastavro | Avro deserialization, Kafka â†’ Bronze in real-time |
| **Batch Processing** | Apache Spark (PySpark) | Medallion transformations (Bronze â†’ Silver â†’ Gold) |
| **Orchestration** | Apache Airflow (CeleryExecutor) | DAG-based pipeline scheduling & monitoring |
| **Data Lake** | Local Parquet files (Medallion Architecture) | Partitioned by ingestion_date |
| **Data Warehouse** | PostgreSQL (Star Schema) | Fact + dimension tables for SQL analytics |
| **Traditional ML** | XGBoost, Scikit-learn, SHAP, Optuna | Classification, explainability, hyperparameter tuning |
| **Deep Learning** | PyTorch (LSTM) | Time-series temperature forecasting |
| **ML Ops** | MLflow | Experiment tracking, model versioning, artifact logging |
| **Gen AI / LLM** | Groq API (Llama 3.1), ChromaDB, LangChain | RAG chatbot, report generation, text-to-SQL |
| **Backend API** | FastAPI | REST API for predictions and chatbot |
| **Frontend** | Streamlit | Interactive dashboard |
| **Containerization** | Docker, Docker Compose | 8+ services orchestrated locally |
| **Cloud Platform** | GCP (GCS, BigQuery, GKE, Vertex AI, Cloud Run) | Production deployment |
| **Infrastructure as Code** | Terraform | Automated GCP resource provisioning |
| **CI/CD** | GitHub Actions | Automated testing, building, deployment |
| **Monitoring** | Prometheus, Grafana | Infrastructure metrics & alerting |
| **Languages** | Python 3.11, SQL, YAML, HCL | Core development |

---

## âœ¨ Features

### Data Engineering
- **Real-time ingestion** from OpenWeatherMap API for 20 US cities via Kafka
- **Avro schema enforcement** with Confluent Schema Registry
- **Medallion data lake** (Bronze â†’ Silver â†’ Gold) with Parquet partitioning
- **Star schema warehouse** in PostgreSQL (fact + 3 dimension tables)
- **Data quality validation** â€” range checks, null handling, deduplication
- **Airflow DAGs** orchestrating the full pipeline on schedule

### Machine Learning
- **Extreme weather classification** with XGBoost (F1 Score: 1.0)
- **Temperature forecasting** with LSTM (MAE: 0.039, RMSE: 0.064)
- **49 engineered features** including heat index, wind chill, anomaly scores
- **SHAP explainability** â€” understand WHY the model predicted extreme weather
- **Optuna hyperparameter tuning** â€” 50 automated trials
- **MLflow experiment tracking** â€” all metrics, parameters, and plots logged

### Generative AI
- **Natural language weather reports** from raw ML predictions via Groq LLM
- **Anomaly explanation engine** â€” LLM explains unusual weather patterns
- **RAG chatbot** â€” ask climate questions grounded in your actual data (ChromaDB)
- **Text-to-SQL** â€” query the warehouse in plain English

### Infrastructure
- **8+ Docker containers** managed via Docker Compose
- **Kafka + Zookeeper + Schema Registry** for streaming infrastructure
- **Spark Master + Worker** for distributed processing
- **Airflow (Webserver + Scheduler + Worker)** for orchestration
- **PostgreSQL + Redis** for metadata and task queuing

### Google Cloud Platform (Production Deployment)
- **Google Cloud Storage (GCS)** â€” Cloud data lake replacing local Parquet (Bronze/Silver/Gold buckets)
- **Google BigQuery** â€” Cloud data warehouse replacing local PostgreSQL
- **Google Kubernetes Engine (GKE)** â€” Container orchestration for all 12+ services
- **Vertex AI** â€” ML model serving with auto-scaling endpoints
- **Cloud Run** â€” Serverless FastAPI + Streamlit deployment
- **Artifact Registry** â€” Docker image storage
- **Terraform** â€” Infrastructure as Code for all GCP resources
- **GitHub Actions** â€” CI/CD pipeline (lint â†’ test â†’ build â†’ deploy)

---

## ğŸ“ Project Structure

```
Climate-Intelligence-Platform-for-Extreme-Weather-Prediction/
â”‚
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ docker-compose.yml                     # All 8+ services (one command startup)
â”œâ”€â”€ .env                                   # API keys & configuration (git-ignored)
â”œâ”€â”€ .env.example                           # Environment template
â”œâ”€â”€ .gitignore                             # Git ignore rules
â”‚
â”œâ”€â”€ data_ingestion/                        # === KAFKA PRODUCERS ===
â”‚   â”œâ”€â”€ Dockerfile                         # Container for producer service
â”‚   â”œâ”€â”€ requirements.txt                   # confluent-kafka, requests, etc.
â”‚   â”œâ”€â”€ kafka_producer_openweather.py      # Production Avro producer (20 cities)
â”‚   â”œâ”€â”€ kafka_producer.py                  # Simple test producer (mock data)
â”‚   â”œâ”€â”€ kafka_consumer.py                  # Simple test consumer
â”‚   â”œâ”€â”€ kafka_consumer_test.py             # Avro consumer for verification
â”‚   â”œâ”€â”€ real_kafka_producer.py             # NOAA-based producer
â”‚   â”œâ”€â”€ noaa_weather_client.py             # NOAA API client
â”‚   â”œâ”€â”€ avro_schemas/
â”‚   â”‚   â”œâ”€â”€ weather_reading.avsc           # Avro schema (16 fields)
â”‚   â”‚   â””â”€â”€ weather_alert.avsc            # Alert schema (10 fields)
â”‚   â””â”€â”€ kafka_connect/
â”‚       â””â”€â”€ gcs_sink_connector.json        # GCS sink config (for cloud deploy)
â”‚
â”œâ”€â”€ data_processing/                       # === SPARK JOBS ===
â”‚   â”œâ”€â”€ spark_streaming_bronze.py          # Kafka â†’ Bronze (Avro â†’ Parquet)
â”‚   â”œâ”€â”€ spark_batch_silver.py              # Bronze â†’ Silver (cleaning)
â”‚   â”œâ”€â”€ spark_batch_gold.py                # Silver â†’ Gold (49 features)
â”‚   â”œâ”€â”€ data_processor.py                  # Utility processor
â”‚   â”œâ”€â”€ init_database.py                   # Database initialization
â”‚   â””â”€â”€ view_data.py                       # Data inspection utility
â”‚
â”œâ”€â”€ orchestration/                         # === AIRFLOW ===
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ climate_pipeline_dag.py        # Main pipeline DAG
â”‚   â”‚   â””â”€â”€ load_warehouse.py              # Gold â†’ PostgreSQL loader
â”‚   â””â”€â”€ sql/
â”‚       â””â”€â”€ create_warehouse.sql           # Star schema DDL
â”‚
â”œâ”€â”€ ml/                                    # === MACHINE LEARNING ===
â”‚   â”œâ”€â”€ train_xgboost.py                   # XGBoost classifier + SHAP + MLflow
â”‚   â”œâ”€â”€ train_lstm.py                      # PyTorch LSTM forecaster + MLflow
â”‚   â”œâ”€â”€ hyperparameter_tuning.py           # Optuna (50 trials) + MLflow
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ lstm_model.pth                 # Saved LSTM weights
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ confusion_matrix.png           # XGBoost confusion matrix
â”‚       â”œâ”€â”€ shap_summary.png               # SHAP feature importance (dots)
â”‚       â”œâ”€â”€ shap_importance.png            # SHAP feature importance (bars)
â”‚       â”œâ”€â”€ lstm_training_loss.png         # LSTM train/val loss curves
â”‚       â””â”€â”€ lstm_predictions.png           # Predicted vs actual temperature
â”‚
â”œâ”€â”€ genai/                                 # === GEN AI (Groq LLM) ===
â”‚   â”œâ”€â”€ report_generator.py                # Predictions â†’ natural language reports
â”‚   â”œâ”€â”€ anomaly_explainer.py               # Anomaly â†’ LLM explanation
â”‚   â”œâ”€â”€ rag_pipeline.py                    # ChromaDB + Groq RAG chatbot
â”‚   â”œâ”€â”€ text_to_sql.py                     # English â†’ SQL â†’ PostgreSQL â†’ answer
â”‚   â”œâ”€â”€ embeddings/                        # Vector store data
â”‚   â””â”€â”€ prompts/                           # Prompt templates
â”‚
â”œâ”€â”€ data/                                  # === DATA LAKE (git-ignored) ===
â”‚   â”œâ”€â”€ bronze/                            # Raw Parquet from Kafka
â”‚   â”‚   â””â”€â”€ weather_readings/
â”‚   â”‚       â””â”€â”€ ingestion_date=2026-02-17/
â”‚   â”œâ”€â”€ silver/                            # Cleaned Parquet
â”‚   â”‚   â””â”€â”€ weather_readings/
â”‚   â”‚       â””â”€â”€ reading_date=2026-02-17/
â”‚   â”œâ”€â”€ gold/                              # Feature-engineered (49 columns)
â”‚   â”‚   â””â”€â”€ weather_features/
â”‚   â”‚       â””â”€â”€ reading_date=2026-02-17/
â”‚   â””â”€â”€ checkpoints/                       # Spark streaming checkpoints
â”‚       â””â”€â”€ bronze/
â”‚
â”œâ”€â”€ mlruns/                                # === MLFLOW (git-ignored) ===
â”‚   â””â”€â”€ (experiment tracking data)
â”‚
â”œâ”€â”€ infrastructure/                        # === DEPLOYMENT (Week 8) ===
â”‚   â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ kubernetes/
â”‚
â”œâ”€â”€ tests/                                 # === TESTS ===
â”‚   â”œâ”€â”€ test_ingestion/
â”‚   â”œâ”€â”€ test_processing/
â”‚   â”œâ”€â”€ test_ml/
â”‚   â”œâ”€â”€ test_genai/
â”‚   â””â”€â”€ test_api/
â”‚
â”œâ”€â”€ scripts/                               # === UTILITY SCRIPTS ===
â”‚   â”œâ”€â”€ setup_local.sh
â”‚   â””â”€â”€ create_kafka_topics.sh
â”‚
â””â”€â”€ docs/                                  # === DOCUMENTATION ===
    â”œâ”€â”€ ARCHITECTURE.md
    â””â”€â”€ DEPLOYMENT.md
```

---

## ğŸš€ Getting Started

### Prerequisites

| Tool | Version | Installation |
|------|---------|-------------|
| Python | 3.11+ | [python.org](https://python.org) |
| Java | 17 (Temurin) | [adoptium.net](https://adoptium.net) |
| Docker Desktop | Latest | [docker.com](https://docker.com/products/docker-desktop) |
| Git | Latest | [git-scm.com](https://git-scm.com) |

### Quick Start (Windows)

```powershell
# 1. Clone the repository
git clone https://github.com/yourusername/Climate-Intelligence-Platform-for-Extreme-Weather-Prediction.git
cd Climate-Intelligence-Platform-for-Extreme-Weather-Prediction

# 2. Create virtual environment
python -m venv venv
.\venv\Scripts\Activate

# 3. Install dependencies
python -m pip install confluent-kafka httpx requests python-dotenv fastavro
python -m pip install pyspark==3.5.1 psycopg2-binary
python -m pip install xgboost scikit-learn mlflow shap optuna torch matplotlib seaborn
python -m pip install groq chromadb langchain langchain-community sentence-transformers

# 4. Copy environment template and add your API keys
copy .env.example .env
# Edit .env with your OPENWEATHER_API_KEY, GROQ_API_KEY

# 5. Set environment variables (required every PowerShell session)
$env:JAVA_HOME = "C:\Program Files\Eclipse Adoptium\jdk-17.0.18.8-hotspot"
$env:PATH = "$env:JAVA_HOME\bin;$env:PATH"
$env:HADOOP_HOME = "C:\hadoop"
$env:PYSPARK_PYTHON = "python"
$env:PYSPARK_DRIVER_PYTHON = "python"

# 6. Start all Docker services
docker-compose up -d

# 7. Verify services are running
docker-compose ps
```

### Access Points (Local)

| Service | URL | Description |
|---------|-----|-------------|
| **Kafka UI** | http://localhost:8888 | Topic monitoring, message browser |
| **Schema Registry** | http://localhost:8081 | Avro schema management |
| **Spark Master** | http://localhost:8090 | Spark job monitoring |
| **Airflow** | http://localhost:8085 | Pipeline orchestration (admin/admin) |
| **MLflow** | http://localhost:5555 | ML experiment tracking |
| **PostgreSQL** | localhost:5432 | Data warehouse (airflow/airflow) |

### Run the Full Pipeline

```powershell
# Terminal 1: Start Kafka producer (sends real weather data)
cd data_ingestion
python kafka_producer_openweather.py

# Terminal 2: Start Spark streaming (Kafka â†’ Bronze)
python data_processing/spark_streaming_bronze.py

# Terminal 3: Run batch processing (after streaming has data)
python data_processing/spark_batch_silver.py
python data_processing/spark_batch_gold.py

# Load into warehouse
python orchestration/dags/load_warehouse.py

# Train ML models
python ml/train_xgboost.py
python ml/hyperparameter_tuning.py
python ml/train_lstm.py

# Run Gen AI features
python genai/report_generator.py
python genai/anomaly_explainer.py
python genai/rag_pipeline.py
python genai/text_to_sql.py
```

---

## ğŸ”„ Pipeline Deep Dive

### Data Flow

```
OpenWeatherMap API (20 cities, every 30 seconds)
       â†“
Kafka Producer (Avro serialization, Schema Registry validation)
       â†“
Apache Kafka (Topic: raw-weather-data, 3 partitions)
       â†“
Spark Structured Streaming (fastavro deserialization)
       â†“
Bronze Layer (Raw Parquet, partitioned by ingestion_date)
       â†“
Spark Batch: Bronze â†’ Silver (dedup, null handling, range validation)
       â†“
Spark Batch: Silver â†’ Gold (heat index, wind chill, anomaly scores, 49 features)
       â†“
PostgreSQL Star Schema (fact_weather_readings + 3 dimension tables)
       â†“
ML Models (XGBoost classification + LSTM forecasting)
       â†“
Gen AI (Groq LLM reports, anomaly explanations, RAG chatbot, text-to-SQL)
```

### Medallion Architecture

| Layer | Records | Columns | Purpose | Partitioning |
|-------|---------|---------|---------|-------------|
| **Bronze** | 660+ | 22 | Raw data from Kafka (untouched) | `ingestion_date` |
| **Silver** | 660 | 28 | Cleaned, validated, quality flagged | `reading_date` |
| **Gold** | 660 | 49 | Feature-engineered, ML-ready | `reading_date` |

### Star Schema (PostgreSQL)

```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   dim_time      â”‚
              â”‚   17,544 rows   â”‚
              â”‚   (hourly 2yr)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dim_location  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤ fact_weather_readings  â”‚
â”‚ 20 cities     â”‚      â”‚      â”‚ 660+ records            â”‚
â”‚ 6 regions     â”‚      â”‚      â”‚ 24 measurements         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚dim_weather_type â”‚
              â”‚ 15 conditions   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– ML Models

### Model Performance

| Model | Task | Key Metric | Value |
|-------|------|-----------|-------|
| **XGBoost** | Extreme weather classification | F1 Score | 1.0000 |
| **XGBoost (Optuna-tuned)** | Same, with optimized hyperparameters | F1 Score | 1.0000 |
| **LSTM** | Temperature forecasting | MAE | 0.0393 |
| **LSTM** | Temperature forecasting | RMSE | 0.0638 |

### Features Used (24 for XGBoost)

Temperature (Â°F, Â°C), humidity, pressure, wind speed/direction, precipitation, visibility, cloud cover, heat index, wind chill, temperature anomaly, anomaly score, city statistics (avg, min, max, stddev), hour of day, day of week, month, is_daytime, latitude, longitude.

### Explainability (SHAP)

SHAP values generated for every prediction, showing which features contributed most to the extreme weather classification. Plots saved to `ml/plots/`.

---

## ğŸ§  Gen AI Integration

| Feature | Technology | What It Does |
|---------|-----------|-------------|
| **Weather Reports** | Groq (Llama 3.1) | ML predictions â†’ Natural language weather intelligence reports |
| **Anomaly Explainer** | Groq (Llama 3.1) | Detects anomalies â†’ Explains WHY in plain English with risks |
| **RAG Chatbot** | ChromaDB + Groq | User asks questions â†’ Retrieves from vector DB â†’ Grounded answer |
| **Text-to-SQL** | Groq + PostgreSQL | English question â†’ SQL query â†’ Execute â†’ Natural language answer |

### Example Interactions

**Report Generator:**
> "Current conditions in Phoenix, AZ show mild weather with a temperature of 71.4Â°F and low humidity at 32%. No extreme weather conditions detected. Conditions are favorable for outdoor activities."

**RAG Chatbot:**
> â“ "Which city has the highest temperature?"
> ğŸ¤– "Based on available data, Honolulu, HI has the highest temperature at 77.99Â°F, followed by Miami, FL at 73.49Â°F."

**Text-to-SQL:**
> â“ "What is the average temperature for each city?"
> ğŸ“ SQL: `SELECT l.city, ROUND(AVG(f.temperature_fahrenheit)::numeric, 1) FROM climate_warehouse.fact_weather_readings f JOIN climate_warehouse.dim_location l ON f.location_key = l.location_key GROUP BY l.city ORDER BY avg DESC LIMIT 20`

---

## ğŸ“Š Docker Services

| Container | Image | Port | Purpose |
|-----------|-------|------|---------|
| zookeeper | confluentinc/cp-zookeeper:7.5.0 | 2181 | Kafka cluster management |
| kafka | confluentinc/cp-kafka:7.5.0 | 9092 | Message broker |
| schema-registry | confluentinc/cp-schema-registry:7.5.0 | 8081 | Avro schema enforcement |
| kafka-ui | provectuslabs/kafka-ui:latest | 8888 | Web dashboard for Kafka |
| spark-master | bitnamilegacy/spark:3.5.1 | 8090, 7077 | Spark job coordinator |
| spark-worker | bitnamilegacy/spark:3.5.1 | â€” | Spark processing |
| postgres | postgres:15 | 5432 | Airflow DB + Data warehouse |
| redis | redis:7-alpine | 6379 | Airflow task broker |
| airflow-webserver | apache/airflow:2.8.1 | 8085 | Pipeline monitoring UI |
| airflow-scheduler | apache/airflow:2.8.1 | â€” | DAG scheduling |
| airflow-worker | apache/airflow:2.8.1 | â€” | Task execution |

---

## ğŸ“… Implementation Roadmap

| Week | Focus | Status | Key Deliverables |
|------|-------|--------|-----------------|
| **1** | Foundation & Kafka | âœ… Done | Docker Compose, Kafka cluster, topics, producer/consumer |
| **2** | Data Ingestion | âœ… Done | Avro schemas, Schema Registry, production Kafka producer |
| **3** | Spark Processing | âœ… Done | Structured Streaming, Medallion Architecture (Bronze/Silver/Gold) |
| **4** | Warehouse & Airflow | âœ… Done | PostgreSQL star schema, Airflow DAGs, warehouse loader |
| **5** | ML Models & MLflow | âœ… Done | XGBoost, LSTM, Optuna, SHAP, MLflow tracking |
| **6** | Gen AI Integration | âœ… Done | Report generator, anomaly explainer, RAG chatbot, text-to-SQL |
| **7** | API & Dashboard | ğŸ”² Next | FastAPI endpoints, Streamlit dashboard |
| **8** | GCP Deployment & CI/CD | ğŸ”² Planned | GCS, BigQuery, GKE, Terraform, GitHub Actions, Grafana |

---

## â˜ï¸ GCP Production Architecture (Week 8)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GOOGLE CLOUD PLATFORM                                  â”‚
â”‚                                                                           â”‚
â”‚   Data Lake: Google Cloud Storage (GCS)                                  â”‚
â”‚     â”œâ”€â”€ gs://climate-bronze/  â†’ Raw Parquet from Kafka Connect           â”‚
â”‚     â”œâ”€â”€ gs://climate-silver/  â†’ Cleaned & validated                      â”‚
â”‚     â””â”€â”€ gs://climate-gold/    â†’ Feature-engineered, ML-ready             â”‚
â”‚                                                                           â”‚
â”‚   Data Warehouse: Google BigQuery                                        â”‚
â”‚     â”œâ”€â”€ climate_warehouse.fact_weather_readings                          â”‚
â”‚     â”œâ”€â”€ climate_warehouse.dim_location                                   â”‚
â”‚     â”œâ”€â”€ climate_warehouse.dim_time                                       â”‚
â”‚     â””â”€â”€ climate_warehouse.dim_weather_type                               â”‚
â”‚                                                                           â”‚
â”‚   ML Serving: Vertex AI Endpoints (auto-scaling)                         â”‚
â”‚     â”œâ”€â”€ XGBoost model endpoint                                           â”‚
â”‚     â””â”€â”€ LSTM model endpoint                                              â”‚
â”‚                                                                           â”‚
â”‚   Container Orchestration: Google Kubernetes Engine (GKE)                 â”‚
â”‚     â”œâ”€â”€ Kafka + Zookeeper + Schema Registry pods                         â”‚
â”‚     â”œâ”€â”€ Spark Master + Worker pods                                       â”‚
â”‚     â”œâ”€â”€ Airflow pods                                                     â”‚
â”‚     â”œâ”€â”€ FastAPI + Streamlit pods                                         â”‚
â”‚     â””â”€â”€ Monitoring (Prometheus + Grafana) pods                           â”‚
â”‚                                                                           â”‚
â”‚   CI/CD: GitHub Actions â†’ Artifact Registry â†’ GKE                        â”‚
â”‚   IaC: Terraform (main.tf, variables.tf, outputs.tf)                    â”‚
â”‚   Monitoring: Prometheus + Grafana dashboards                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GCP Deployment Commands (Week 8)

```bash
# 1. Set up GCP infrastructure with Terraform
cd infrastructure/terraform
terraform init
terraform plan
terraform apply

# 2. Build & push Docker images to Artifact Registry
bash scripts/build_and_push.sh

# 3. Deploy to GKE
kubectl apply -f infrastructure/kubernetes/

# 4. Verify deployment
kubectl get pods -n climate-platform
```

---

## ğŸ“ Why This Project Stands Out

- **End-to-end pipeline**: From raw API data â†’ Kafka â†’ Spark â†’ ML â†’ Gen AI â†’ SQL analytics
- **Production-grade**: Avro schemas, dead letter queues, data quality validation, MLflow tracking
- **Real data**: 20 US cities with real OpenWeatherMap data, not synthetic/mock data
- **Modern stack**: Kafka streaming + Spark + XGBoost/LSTM + Groq LLM + ChromaDB RAG
- **Explainable AI**: SHAP values show WHY the model predicted extreme weather
- **Gen AI powered**: Natural language reports, anomaly explanations, chatbot, text-to-SQL
- **Orchestrated**: Airflow DAGs automate the entire pipeline
- **49 ML features**: Heat index, wind chill, anomaly scores, time features, city statistics
- **Cloud-ready**: Designed for GCP deployment (GCS, BigQuery, GKE, Vertex AI, Terraform)

---

## ğŸ”‘ Environment Variables

```env
# Weather API
OPENWEATHER_API_KEY=your_key_here

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
SCHEMA_REGISTRY_URL=http://localhost:8081

# Gen AI
GROQ_API_KEY=your_groq_key_here

# MLflow
MLFLOW_TRACKING_URI=file:./mlruns

# PostgreSQL (local warehouse)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# GCP Configuration (for Week 8 deployment)
GCP_PROJECT_ID=your_gcp_project_id
GCP_REGION=us-central1
GCS_BUCKET_BRONZE=climate-bronze
GCS_BUCKET_SILVER=climate-silver
GCS_BUCKET_GOLD=climate-gold
BIGQUERY_DATASET=climate_warehouse
```

---

## ğŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

*Built with â¤ï¸ for climate resilience*
