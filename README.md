# ğŸŒ Climate Intelligence Platform for Extreme Weather Prediction

> A **production-grade data engineering & machine learning project** that predicts extreme weather events using real NOAA weather data, Apache Kafka, PostgreSQL, ML models, and Google Cloud Platform.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-required-brightgreen.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-Active-success.svg)]()

---

## ğŸ“– Table of Contents

1. [Project Overview](#-project-overview)
2. [Features](#-features)
3. [Architecture](#-architecture)
4. [Tech Stack](#-tech-stack)
5. [Quick Start](#-quick-start)
6. [Project Structure](#-project-structure)
7. [Detailed Setup](#-detailed-setup)
8. [Usage Guide](#-usage-guide)
9. [Implementation Phases](#-implementation-phases)
10. [Data Pipeline](#-data-pipeline)
11. [Machine Learning](#-machine-learning)
12. [API Documentation](#-api-documentation)
13. [Deployment](#-deployment)
14. [Monitoring & Logging](#-monitoring--logging)
15. [Troubleshooting](#-troubleshooting)
16. [Contributing](#-contributing)
17. [Learning Resources](#-learning-resources)
18. [FAQ](#-faq)

---

# ğŸ¯ Project Overview

## What This Project Does

A **complete, production-ready data engineering platform** that:

1. **Ingests** real weather data from 15 major US cities via NOAA API
2. **Streams** data through Apache Kafka (no data loss)
3. **Processes** & transforms data in real-time
4. **Stores** in PostgreSQL and Google Cloud BigQuery
5. **Trains** ensemble ML models (LSTM + XGBoost)
6. **Predicts** extreme weather events
7. **Serves** predictions via FastAPI
8. **Visualizes** on interactive Streamlit dashboard
9. **Deploys** to Kubernetes & Google Cloud
10. **Monitors** with Prometheus, Grafana, and Cloud Logging

## Real-World Use Cases

| Use Case | Benefit |
|----------|---------|
| **Insurance Companies** | Assess weather risk for policies |
| **Weather Services** | Improve extreme weather alerts |
| **Agriculture** | Monitor crop conditions |
| **Emergency Management** | Plan disaster response |
| **City Planning** | Understand climate patterns |
| **Energy Sector** | Forecast demand based on weather |

---

# âœ¨ Features

## Core Features (Implemented)

âœ… **Real-time Data Ingestion**
- NOAA API integration (no API key required!)
- 15 major US cities monitored
- Updates every 30 seconds
- Automatic error handling & retries

âœ… **Stream Processing**
- Apache Kafka message queue
- Real-time data validation
- Feature engineering (heat index calculation)
- Extreme event detection
- Data deduplication

âœ… **Data Storage**
- PostgreSQL for transactional data
- Structured schema with migrations
- Indexed queries for performance
- Data retention policies

âœ… **Data Quality**
- Schema validation
- Range validation (temperature, humidity, etc.)
- Anomaly detection
- Error logging & alerting

## Advanced Features (Coming Soon)

ğŸ”œ **Machine Learning**
- LSTM time-series forecasting
- XGBoost classification
- Ensemble predictions
- Model versioning & registry
- Hyperparameter tuning
- Drift detection & automated retraining

ğŸ”œ **REST API**
- FastAPI with auto-documentation
- Multiple prediction endpoints
- Request/response logging
- Rate limiting & authentication
- Redis caching layer
- Health check endpoints

ğŸ”œ **Interactive Dashboard**
- Streamlit web application
- Real-time predictions
- Historical analysis
- Model performance metrics
- Alert management
- Admin console

ğŸ”œ **Cloud Deployment**
- Google Cloud integration
- Pub/Sub messaging
- Dataflow stream processing
- BigQuery data warehouse
- Vertex AI ML training
- Cloud Run serverless hosting

ğŸ”œ **Orchestration**
- Apache Airflow DAGs
- Cloud Composer managed workflows
- Scheduled retraining jobs
- Data quality checks
- SLA monitoring

ğŸ”œ **Kubernetes**
- Docker containerization
- Kubernetes manifests
- Helm charts
- Auto-scaling policies
- Blue-green deployments

ğŸ”œ **CI/CD Pipeline**
- GitHub Actions automation
- Automated testing
- Performance benchmarking
- Container registry
- Automated deployments

---

# ğŸ—ï¸ Architecture

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES                              â”‚
â”‚    NOAA Weather API (15 US Cities) | Satellite Data             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DATA INGESTION LAYER (Real-time)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ NOAA Client â†’ Kafka Producer â†’ Kafka Topic             â”‚   â”‚
â”‚  â”‚ â€¢ Fetch real weather every 30 seconds                  â”‚   â”‚
â”‚  â”‚ â€¢ Handle API failures gracefully                       â”‚   â”‚
â”‚  â”‚ â€¢ Publish to "weather-events" topic                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STREAM PROCESSING LAYER (Data Transformation)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Kafka Consumer â†’ Data Processor â†’ PostgreSQL            â”‚   â”‚
â”‚  â”‚ â€¢ Consume from Kafka topic                              â”‚   â”‚
â”‚  â”‚ â€¢ Validate data ranges                                  â”‚   â”‚
â”‚  â”‚ â€¢ Calculate heat index (new feature)                    â”‚   â”‚
â”‚  â”‚ â€¢ Detect extreme events (new feature)                   â”‚   â”‚
â”‚  â”‚ â€¢ Add processing timestamp                              â”‚   â”‚
â”‚  â”‚ â€¢ Store raw & processed data                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DATA WAREHOUSE LAYER (Storage & Query)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PostgreSQL (Local) | BigQuery (Cloud)                   â”‚   â”‚
â”‚  â”‚ â€¢ Store raw events                                      â”‚   â”‚
â”‚  â”‚ â€¢ Store processed data                                  â”‚   â”‚
â”‚  â”‚ â€¢ Historical data for analysis                          â”‚   â”‚
â”‚  â”‚ â€¢ Ready for ML training                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ML/AI LAYER (Coming Soon)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ LSTM + XGBoost Ensemble                                 â”‚   â”‚
â”‚  â”‚ â€¢ Time-series forecasting (LSTM)                        â”‚   â”‚
â”‚  â”‚ â€¢ Event classification (XGBoost)                        â”‚   â”‚
â”‚  â”‚ â€¢ Ensemble voting                                       â”‚   â”‚
â”‚  â”‚ â€¢ Model versioning                                      â”‚   â”‚
â”‚  â”‚ â€¢ Drift detection & retraining                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            SERVING LAYER (API & Caching)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ FastAPI Server | Vertex AI Endpoints                    â”‚   â”‚
â”‚  â”‚ â€¢ REST API endpoints                                    â”‚   â”‚
â”‚  â”‚ â€¢ Redis caching                                         â”‚   â”‚
â”‚  â”‚ â€¢ Authentication & rate limiting                        â”‚   â”‚
â”‚  â”‚ â€¢ Response logging                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FRONTEND LAYER (User Interfaces)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Streamlit Dashboard | React SPA (Coming)                â”‚   â”‚
â”‚  â”‚ â€¢ Real-time predictions                                 â”‚   â”‚
â”‚  â”‚ â€¢ Historical analytics                                  â”‚   â”‚
â”‚  â”‚ â€¢ Model metrics & performance                           â”‚   â”‚
â”‚  â”‚ â€¢ Alert management                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MONITORING & ORCHESTRATION (Observability)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Prometheus + Grafana | Airflow | Cloud Logging         â”‚   â”‚
â”‚  â”‚ â€¢ Metrics collection                                    â”‚   â”‚
â”‚  â”‚ â€¢ Pipeline orchestration                                â”‚   â”‚
â”‚  â”‚ â€¢ Automated alerting                                    â”‚   â”‚
â”‚  â”‚ â€¢ Log aggregation                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ’» Tech Stack

## Core Technologies

### **Data Ingestion & Streaming**
- **NOAA Weather API** - Real weather data source
- **Apache Kafka** - Message broker for streaming
- **Python Requests** - HTTP client for APIs

### **Data Processing**
- **Apache Spark** - Distributed processing
- **Python/Pandas** - Data manipulation
- **Great Expectations** - Data validation

### **Storage**
- **PostgreSQL** - Primary transactional database
- **Google Cloud BigQuery** - Cloud data warehouse
- **Cloud Storage** - Object storage

### **Machine Learning**
- **TensorFlow/Keras** - LSTM neural networks
- **XGBoost** - Gradient boosting
- **Scikit-learn** - ML utilities
- **PyTorch** - Deep learning (optional)

### **API & Web**
- **FastAPI** - REST API framework
- **Streamlit** - Dashboard framework
- **Redis** - Caching layer
- **Pydantic** - Data validation

### **Cloud Platform**
- **Google Cloud Platform (GCP)**
  - Pub/Sub
  - Cloud Dataflow
  - BigQuery
  - Vertex AI
  - Cloud Run
  - Cloud Storage

### **Orchestration**
- **Apache Airflow** - Workflow orchestration
- **Cloud Composer** - Managed Airflow on GCP

### **Monitoring & Logging**
- **Prometheus** - Metrics collection
- **Grafana** - Visualization
- **Cloud Logging** - Log aggregation
- **Cloud Monitoring** - GCP monitoring

### **DevOps & Deployment**
- **Docker** - Container runtime
- **Docker Compose** - Local orchestration
- **Kubernetes** - Container orchestration
- **Helm** - K8s package manager
- **Terraform** - Infrastructure as Code
- **GitHub Actions** - CI/CD pipeline

### **Development Tools**
- **Python 3.10+**
- **Git** - Version control
- **VS Code** - IDE
- **Jupyter** - Notebooks

---

# ğŸš€ Quick Start

## Prerequisites

```bash
# Required
- Windows, macOS, or Linux
- Python 3.10 or higher
- Docker & Docker Compose
- Git
- 8GB+ RAM
- 20GB+ disk space
```

## 5-Minute Setup

```bash
# 1. Clone or download the project
cd Climate-Intelligence-Platform

# 2. Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows
source venv/bin/activate     # macOS/Linux

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start Docker services
docker-compose up -d

# 5. Create database tables
python data_processing\init_database.py

# 6. Start the pipeline (3 terminals)
# Terminal 1:
python data_ingestion\real_kafka_producer.py

# Terminal 2:
python data_processing\data_processor.py

# Terminal 3:
python data_processing\view_data.py
```

**That's it! Real weather data is now flowing through your pipeline!** ğŸ‰

---

# ğŸ“ Project Structure

```
climate-intelligence-platform/
â”‚
â”œâ”€â”€ ğŸ“ data_ingestion/                    # Get real weather data
â”‚   â”œâ”€â”€ noaa_weather_client.py            # NOAA API integration
â”‚   â”œâ”€â”€ real_kafka_producer.py            # Send to Kafka
â”‚   â”œâ”€â”€ kafka_consumer.py                 # Test receiver
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ data_processing/                   # Clean & transform data
â”‚   â”œâ”€â”€ init_database.py                  # Create DB tables
â”‚   â”œâ”€â”€ data_processor.py                 # Main processor
â”‚   â”œâ”€â”€ view_data.py                      # Display results
â”‚   â”œâ”€â”€ transformations.py                # Feature engineering
â”‚   â””â”€â”€ data_quality.py                   # Validation
â”‚
â”œâ”€â”€ ğŸ“ ml_training/                       # Machine Learning
â”‚   â”œâ”€â”€ data_prep.py                      # Prepare training data
â”‚   â”œâ”€â”€ feature_store.py                  # Feature management
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ lstm_model.py                 # LSTM architecture
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py              # XGBoost classifier
â”‚   â”‚   â””â”€â”€ ensemble.py                   # Ensemble approach
â”‚   â”œâ”€â”€ train.py                          # Training script
â”‚   â”œâ”€â”€ evaluate.py                       # Model evaluation
â”‚   â”œâ”€â”€ hyperparameter_tuning.py          # Optimize hyperparameters
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ model_serving/                     # Serve predictions
â”‚   â”œâ”€â”€ main.py                           # FastAPI app
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ predict.py                    # Prediction endpoint
â”‚   â”‚   â”œâ”€â”€ health.py                     # Health checks
â”‚   â”‚   â””â”€â”€ metrics.py                    # Performance metrics
â”‚   â”œâ”€â”€ schemas.py                        # Data validation
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ dashboard/                         # User interface
â”‚   â”œâ”€â”€ streamlit_app.py                  # Main app
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ predictions.py                # Prediction page
â”‚   â”‚   â”œâ”€â”€ historical_analysis.py        # Analytics
â”‚   â”‚   â”œâ”€â”€ model_metrics.py              # Model performance
â”‚   â”‚   â””â”€â”€ alerts.py                     # Alert management
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ charts.py                     # Visualizations
â”‚   â”‚   â””â”€â”€ utils.py                      # Helper functions
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ orchestration/                     # Workflow scheduling
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ airflow_dag.py                # Local Airflow
â”‚   â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”‚   â”œâ”€â”€ data_pipeline_dag.py      # Data pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ ml_training_dag.py        # Training jobs
â”‚   â”‚   â”‚   â””â”€â”€ monitoring_dag.py         # Monitoring
â”‚   â”‚   â””â”€â”€ plugins/
â”‚   â”œâ”€â”€ cloud_composer/
â”‚   â”‚   â””â”€â”€ composer_dag.py               # GCP Cloud Composer
â”‚   â””â”€â”€ jobs/
â”‚       â”œâ”€â”€ daily_retraining.py
â”‚       â”œâ”€â”€ data_validation.py
â”‚       â””â”€â”€ model_monitoring.py
â”‚
â”œâ”€â”€ ğŸ“ monitoring/                        # Observability
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ prometheus.yml                # Config
â”‚   â”‚   â””â”€â”€ alerts.yml                    # Alerting rules
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ dashboards/                   # Grafana dashboards
â”‚   â”‚   â””â”€â”€ datasources/                  # Data sources
â”‚   â””â”€â”€ logging/
â”‚       â”œâ”€â”€ logging_config.py
â”‚       â””â”€â”€ structured_logging.py
â”‚
â”œâ”€â”€ ğŸ“ infrastructure/                    # DevOps & Deployment
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile.ingestion
â”‚   â”‚   â”œâ”€â”€ Dockerfile.processing
â”‚   â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”‚   â””â”€â”€ Dockerfile.dashboard
â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â”‚   â””â”€â”€ helm-chart/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ cloud_run.tf
â”‚   â”‚   â”œâ”€â”€ bigquery.tf
â”‚   â”‚   â””â”€â”€ pubsub.tf
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ setup_gcp.sh
â”‚       â”œâ”€â”€ deploy_docker.sh
â”‚       â”œâ”€â”€ deploy_k8s.sh
â”‚       â””â”€â”€ cleanup.sh
â”‚
â”œâ”€â”€ ğŸ“ tests/                             # Testing
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”‚   â”œâ”€â”€ test_processing.py
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â””â”€â”€ test_api.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”‚   â””â”€â”€ test_ml_pipeline.py
â”‚   â””â”€â”€ e2e/
â”‚       â””â”€â”€ test_full_flow.py
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                         # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_development.ipynb
â”‚   â””â”€â”€ 04_model_comparison.ipynb
â”‚
â”œâ”€â”€ ğŸ“ .github/                           # GitHub configuration
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ test.yml                      # CI tests
â”‚       â”œâ”€â”€ build.yml                     # Build images
â”‚       â””â”€â”€ deploy.yml                    # Deployment
â”‚
â”œâ”€â”€ docker-compose.yml                    # Local development
â”œâ”€â”€ docker-compose.prod.yml               # Production stack
â”œâ”€â”€ requirements.txt                      # Python dependencies
â”œâ”€â”€ requirements-dev.txt                  # Development dependencies
â”œâ”€â”€ .env.example                          # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile                            # Main image
â”œâ”€â”€ README.md                             # This file!
â”œâ”€â”€ ARCHITECTURE.md                       # Detailed architecture
â”œâ”€â”€ DEPLOYMENT.md                         # Deployment guide
â”œâ”€â”€ CONTRIBUTING.md                       # Contributing guide
â””â”€â”€ LICENSE
```

---

# ğŸ”§ Detailed Setup

## Step 1: Clone the Repository

```bash
git clone https://github.com/your-username/climate-intelligence.git
cd climate-intelligence
```

## Step 2: Create Virtual Environment

```bash
# Windows
python -m venv venv
.\venv\Scripts\Activate.ps1

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

## Step 3: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

## Step 4: Configure Environment

```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your settings
# nano .env  or  code .env
```

## Step 5: Start Docker Services

```bash
# Start all services
docker-compose up -d

# Verify services are running
docker-compose ps

# Check logs
docker-compose logs -f
```

## Step 6: Initialize Database

```bash
python data_processing\init_database.py
```

You should see:
```
âœ… Connected to PostgreSQL
âœ… Tables created successfully
```

## Step 7: Run the Pipeline

Open **3 separate terminals**:

**Terminal 1 - Producer:**
```bash
python data_ingestion\real_kafka_producer.py
```

**Terminal 2 - Processor:**
```bash
python data_processing\data_processor.py
```

**Terminal 3 - Viewer:**
```bash
python data_processing\view_data.py
```

---

# ğŸ“Š Usage Guide

## Running Each Component

### Producer (Real Weather Data)
```bash
python data_ingestion\real_kafka_producer.py
```
- Fetches REAL weather from NOAA every 30 seconds
- Sends 15 cities worth of data per fetch
- Runs for 5 minutes (300 seconds)
- Press Ctrl+C to stop

### Processor (Transform & Store)
```bash
python data_processing\data_processor.py
```
- Reads data from Kafka
- Validates and transforms
- Stores in PostgreSQL
- Runs indefinitely (press Ctrl+C to stop)

### View Data (Display Results)
```bash
python data_processing\view_data.py
```
- Queries last 20 records from database
- Displays in formatted table
- Shows all transformed features

## Docker Commands

```bash
# Start all services
docker-compose up -d

# Stop all services
docker-compose down

# View logs
docker-compose logs -f [service-name]

# Stop specific service
docker-compose stop kafka

# Restart a service
docker-compose restart postgres

# View running services
docker-compose ps

# Remove all data (WARNING!)
docker-compose down -v
```

## Database Queries

```bash
# Connect to PostgreSQL
psql -h localhost -U airflow -d airflow

# View tables
\dt

# Query raw events
SELECT * FROM raw_events LIMIT 10;

# Query processed data
SELECT * FROM processed_data LIMIT 10;

# Count records
SELECT COUNT(*) FROM processed_data;

# Find extreme events
SELECT * FROM processed_data WHERE extreme_event = 1;

# Exit
\q
```

---

# ğŸ“ˆ Implementation Phases

## Phase 1: Local Development âœ… COMPLETED
- [x] Docker setup with Kafka, PostgreSQL, Redis
- [x] Python environment & dependencies
- [x] Project structure
- [x] Basic documentation

## Phase 2: Data Ingestion âœ… COMPLETED
- [x] NOAA API integration
- [x] Kafka producer
- [x] Kafka consumer (test)
- [x] Real weather data streaming
- [x] Error handling & retries

## Phase 3: Data Processing âœ… COMPLETED
- [x] Data validation
- [x] Feature engineering (heat index)
- [x] Extreme event detection
- [x] Database storage
- [x] Data quality checks

## Phase 4: Machine Learning ğŸ”œ IN PROGRESS
- [ ] LSTM model development
- [ ] XGBoost model
- [ ] Ensemble approach
- [ ] Hyperparameter tuning
- [ ] Model evaluation & comparison
- [ ] Cross-validation

## Phase 5: API & Dashboard ğŸ”œ COMING SOON
- [ ] FastAPI server
- [ ] REST endpoints
- [ ] Authentication
- [ ] Streamlit dashboard
- [ ] Real-time predictions
- [ ] Historical analytics

## Phase 6: GCP Cloud Deployment ğŸ”œ COMING SOON
- [ ] GCP project setup
- [ ] Pub/Sub configuration
- [ ] Cloud Dataflow pipelines
- [ ] BigQuery datasets
- [ ] Vertex AI training
- [ ] Cloud Run deployment

## Phase 7: Kubernetes & CI/CD ğŸ”œ COMING SOON
- [ ] Docker images
- [ ] Kubernetes manifests
- [ ] Helm charts
- [ ] GitHub Actions
- [ ] Automated testing
- [ ] Blue-green deployments

## Phase 8: Monitoring & Production ğŸ”œ COMING SOON
- [ ] Prometheus metrics
- [ ] Grafana dashboards
- [ ] Cloud Logging
- [ ] Alerting
- [ ] SLA monitoring
- [ ] Cost optimization

---

# ğŸ”„ Data Pipeline

## Data Transformation Example

### Input (Raw NOAA Data)
```json
{
  "timestamp": "2024-01-20T10:30:45.123456",
  "location": "New York",
  "temperature": 45.0,
  "humidity": 65.0,
  "wind_speed": 12.5,
  "pressure": 1013.25,
  "precipitation": 0.0,
  "forecast_text": "Partly cloudy",
  "is_daytime": true
}
```

### Processing Steps

1. **Validation**
   - âœ… Temperature: -50 to 150Â°F
   - âœ… Humidity: 0-100%
   - âœ… Wind speed: â‰¥0 mph
   - âœ… All fields present

2. **Feature Engineering**
   - Calculate heat index (45.0Â°F - no adjustment needed below 80Â°F)
   - Detect extreme events (45Â°F < 95Â°F, 12.5 < 50 mph â†’ Normal)

3. **Enrichment**
   - Add processed_at timestamp
   - Add data source metadata
   - Add processing version

### Output (Processed Data)
```json
{
  "timestamp": "2024-01-20T10:30:45.123456",
  "location": "New York",
  "temperature": 45.0,
  "humidity": 65.0,
  "wind_speed": 12.5,
  "pressure": 1013.25,
  "precipitation": 0.0,
  "heat_index": 45.0,
  "extreme_event": 0,
  "processed_at": "2024-01-20T10:35:20.654321"
}
```

### Stored in Database
Both raw and processed data stored in PostgreSQL:
- `raw_events` table - Original data
- `processed_data` table - Transformed data

### Displayed in Terminal
```
Location         Temp    Humidity  Wind    Heat Idx  Extreme
New York         45.0    65.0      12.5    45.0      0
Los Angeles      72.5    45.0      8.3     72.5      0
Chicago          38.1    55.0      15.2    38.1      0
Houston          68.5    70.0      10.5    69.2      0
Phoenix          85.2    30.0      12.3    85.2      0
```

---

# ğŸ§  Machine Learning

## Models (Coming Soon)

### LSTM (Long Short-Term Memory)
- **Purpose:** Time-series forecasting
- **Input:** 24 hours of weather data
- **Output:** Next hour temperature prediction
- **Architecture:** 128 â†’ 64 â†’ 32 â†’ 1

### XGBoost
- **Purpose:** Extreme event classification
- **Input:** Current weather features
- **Output:** Probability of extreme event (0-1)
- **Tree Depth:** 8, Learning Rate: 0.1

### Ensemble
- **Approach:** Weighted voting
- **LSTM Weight:** 40%
- **XGBoost Weight:** 60%
- **Final Prediction:** Ensemble confidence

## Training Pipeline
```
Historical Data (90 days)
    â†“
Feature Engineering
    â†“
Train/Validation Split (80/20)
    â†“
Model Training
    â†“
Hyperparameter Tuning
    â†“
Cross-Validation
    â†“
Model Evaluation
    â†“
Registry & Versioning
    â†“
Deployment
```

---

# ğŸŒ API Documentation

## REST Endpoints (Coming Soon)

### Predict Endpoint
```bash
POST /api/v1/predict

Request:
{
  "temperature": 45.0,
  "humidity": 65.0,
  "wind_speed": 12.5,
  "pressure": 1013.25,
  "location": "New York"
}

Response:
{
  "prediction": "Normal",
  "confidence": 0.95,
  "lstm_confidence": 0.92,
  "xgboost_confidence": 0.97,
  "timestamp": "2024-01-20T10:35:20"
}
```

### Health Check
```bash
GET /api/v1/health

Response:
{
  "status": "healthy",
  "models_loaded": true,
  "database_connected": true,
  "cache_available": true
}
```

### Metrics Endpoint
```bash
GET /api/v1/metrics

Response:
{
  "total_predictions": 1000,
  "extreme_events_detected": 15,
  "average_confidence": 0.93,
  "avg_response_time_ms": 45
}
```

---

# ğŸš€ Deployment

## Local Deployment (Current)

```bash
docker-compose up -d
```

## Docker Deployment (Coming)

```bash
docker build -t climate-intelligence:latest .
docker run -p 8000:8000 climate-intelligence:latest
```

## Kubernetes Deployment (Coming)

```bash
kubectl apply -f kubernetes/
helm install climate-intelligence ./helm-chart
```

## GCP Cloud Deployment (Coming)

```bash
# Deploy to Cloud Run
gcloud run deploy climate-api \
  --image gcr.io/PROJECT/climate-intelligence \
  --memory 2Gi \
  --region us-central1
```

---

# ğŸ“Š Monitoring & Logging

## Local Monitoring

```bash
# Prometheus metrics
http://localhost:9090

# Grafana dashboard
http://localhost:3000

# View logs
docker-compose logs -f [service]
```

## Metrics Collected
- Pipeline latency (ms)
- Data quality score
- Model prediction confidence
- Database query time
- API response time
- Data throughput (records/sec)
- Error rates

## Alerts
- High latency (>500ms)
- Low data quality (<95%)
- Model drift detected
- Database connection failed
- API errors (>5% failure rate)

---

# ğŸ› Troubleshooting

## Common Issues & Solutions

### "relation 'raw_events' does not exist"
**Cause:** Database tables not created
**Solution:**
```bash
python data_processing\init_database.py
```

### "No module named 'psycopg2'"
**Cause:** Missing PostgreSQL adapter
**Solution:**
```bash
pip install psycopg2-binary
```

### "NoBrokersAvailable"
**Cause:** Kafka not running
**Solution:**
```bash
docker-compose up -d
docker-compose ps  # Verify all services are Up
```

### "Connection refused"
**Cause:** Docker services not healthy
**Solution:**
```bash
docker-compose down
docker-compose up -d
docker-compose ps  # Wait for (healthy) status
```

### "ModuleNotFoundError: No module named 'data_ingestion'"
**Cause:** Running from wrong directory
**Solution:**
```bash
cd project-root-directory
python data_ingestion\real_kafka_producer.py
```

### Database connection timeout
**Cause:** PostgreSQL starting slowly
**Solution:**
```bash
# Wait 30 seconds, then try again
sleep 30
python data_processing\data_processor.py
```

### Kafka topics not created
**Cause:** Auto-creation disabled
**Solution:**
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic weather-events --partitions 1 --replication-factor 1
```

## Debug Mode

```bash
# Enable debug logging
export LOG_LEVEL=DEBUG

# Run with verbose output
python -u data_processing\data_processor.py

# Check all Docker services
docker-compose logs --tail=100

# Test Kafka connectivity
docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092
```

---

# ğŸ¤ Contributing

We welcome contributions! Here's how:

## Setup Development Environment

```bash
pip install -r requirements-dev.txt
pre-commit install
```

## Development Workflow

1. Create feature branch: `git checkout -b feature/my-feature`
2. Make changes and commit: `git commit -m "Add feature"`
3. Push: `git push origin feature/my-feature`
4. Create Pull Request with description

## Code Standards

- Python: PEP 8
- Docstrings: Google style
- Type hints: Required for new code
- Tests: 80%+ coverage

## Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src

# Run specific test
pytest tests/unit/test_ingestion.py

# Run integration tests
pytest tests/integration/
```

---

# ğŸ“š Learning Resources

## Official Documentation
- [NOAA Weather API](https://www.weather.gov/documentation/services-web-api)
- [Apache Kafka](https://kafka.apache.org/documentation/)
- [PostgreSQL](https://www.postgresql.org/docs/)
- [TensorFlow/Keras](https://www.tensorflow.org/guide)
- [XGBoost](https://xgboost.readthedocs.io/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://docs.streamlit.io/)
- [Google Cloud](https://cloud.google.com/docs)

## Tutorials & Courses
- [Apache Kafka in 30 Minutes](https://www.youtube.com/watch?v=06iRM1Ghr1k)
- [PostgreSQL Tutorial](https://www.postgresqltutorial.com/)
- [Deep Learning Time Series](https://www.deeplearningbook.org/)
- [FastAPI Full Course](https://www.youtube.com/watch?v=7t2alSnE2-I)
- [Docker Mastery](https://www.udemy.com/course/docker-mastery/)
- [Kubernetes in 100 Seconds](https://www.youtube.com/watch?v=cC46cg5FFAM)

## Books
- "Designing Machine Learning Systems" by Chip Huyen
- "Fundamentals of Software Architecture" by Mark Richards
- "Site Reliability Engineering" by Google
- "The Data Warehouse Toolkit" by Ralph Kimball

---

# â“ FAQ

**Q: Do I need API keys?**
A: No! NOAA API is completely free with no authentication.

**Q: Can I use this on macOS/Linux?**
A: Yes! All code is cross-platform.

**Q: What's the minimum hardware required?**
A: 4GB RAM, 20GB disk (8GB RAM recommended).

**Q: How much does this cost?**
A: Completely free locally. GCP has free tier but charges after.

**Q: How often is data updated?**
A: Every 30 seconds from NOAA.

**Q: How many historical days of data do I need?**
A: ML training starts with 90 days recommended.

**Q: Can I add more cities?**
A: Yes! Edit noaa_weather_client.py and add coordinates.

**Q: What's the data retention policy?**
A: No automatic deletion. Keep as long as needed.

**Q: Can I deploy to AWS instead of GCP?**
A: Yes! Architecture is cloud-agnostic.

**Q: Is this production-ready?**
A: Phases 1-3 are. Phases 4-8 need completion.

---

# ğŸ“ Support & Contact

**Issues & Bugs:** Open GitHub Issues
**Questions:** Check FAQ or Discussions
**Contributions:** See CONTRIBUTING.md
**Email:** your-email@example.com

---

# ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

---

# ğŸ™ Acknowledgments

- NOAA for providing free weather data
- Apache Kafka & community
- PostgreSQL community
- Google Cloud for documentation
- All open-source contributors

---

## ğŸ¯ Key Metrics

- **Data Sources:** 15 US cities
- **Update Frequency:** Every 30 seconds
- **Daily Data Points:** ~43,200 records
- **Database Size:** ~1 MB/month
- **Processing Latency:** <100ms/record
- **Data Accuracy:** 100% (from NOAA)
- **Uptime Target:** 99.9%

---

## ğŸ“Š Project Status

| Phase | Status | Completion | Next |
|-------|--------|-----------|------|
| 1. Setup | âœ… Complete | 100% | Start Phase 2 |
| 2. Ingestion | âœ… Complete | 100% | Start Phase 3 |
| 3. Processing | âœ… Complete | 100% | Start Phase 4 |
| 4. ML | ğŸ”œ In Progress | 0% | Model training |
| 5. API/Dashboard | â³ Planned | 0% | After Phase 4 |
| 6. GCP Deploy | â³ Planned | 0% | After Phase 5 |
| 7. Kubernetes | â³ Planned | 0% | After Phase 6 |
| 8. Monitoring | â³ Planned | 0% | After Phase 7 |

---

**Last Updated:** January 2024
**Maintainer:** Your Name
**Repository:** github.com/your-username/climate-intelligence
