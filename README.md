# ğŸŒ Climate Intelligence Platform for Extreme Weather Prediction

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-3.6-red.svg)](https://kafka.apache.org)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5-orange.svg)](https://spark.apache.org)
[![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED.svg)](https://docker.com)
[![GCP](https://img.shields.io/badge/GCP-Deployed-4285F4.svg)](https://cloud.google.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> A production-grade, end-to-end climate intelligence platform that ingests real-time weather data, processes it through a medallion data lake, predicts extreme weather events using ML/Deep Learning, and provides Gen AI-powered natural language insights â€” all deployed on Google Cloud Platform with Docker & Kubernetes.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Features](#features)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Pipeline Deep Dive](#pipeline-deep-dive)
- [ML Models](#ml-models)
- [Gen AI Integration](#gen-ai-integration)
- [Deployment](#deployment)
- [Monitoring](#monitoring)
- [API Documentation](#api-documentation)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

### The Problem
Extreme weather events (heatwaves, floods, hurricanes, storms) are increasing in frequency and severity. Early prediction can save lives, reduce economic damage, and help communities prepare. Current systems often lack real-time processing, explainability, and accessible interfaces for non-technical users.

### The Solution
This platform combines **real-time data engineering**, **machine learning**, and **generative AI** to:
- Ingest live weather streams from multiple sources via Apache Kafka
- Process terabytes of climate data using Apache Spark (batch + streaming)
- Predict extreme weather events 24-72 hours in advance using ensemble ML models
- Generate human-readable weather intelligence reports using LLMs
- Allow users to query climate data in natural language via a RAG-powered chatbot

### Who Is This For?
- Emergency response agencies needing early warning systems
- Insurance companies assessing climate risk
- Researchers studying extreme weather patterns
- City planners building climate-resilient infrastructure

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA SOURCES                                     â”‚
â”‚   NOAA API  â”‚  OpenWeatherMap API  â”‚  NASA Satellite  â”‚  Weather CSVs    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 INGESTION LAYER (Real-Time Streaming)                     â”‚
â”‚                                                                           â”‚
â”‚   Python Kafka Producers â”€â”€â†’ Apache Kafka (3-Broker Cluster)             â”‚
â”‚                                â”œâ”€â”€ Topic: raw-weather-data               â”‚
â”‚                                â”œâ”€â”€ Topic: weather-alerts                 â”‚
â”‚                                â””â”€â”€ Topic: satellite-metadata             â”‚
â”‚                                                                           â”‚
â”‚   Confluent Schema Registry (Avro) â”€â”€ Data contracts & validation        â”‚
â”‚   Kafka Connect â”€â”€ GCS Sink Connector (raw archival)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROCESSING LAYER (Batch + Stream)                            â”‚
â”‚                                                                           â”‚
â”‚   Spark Structured Streaming                                             â”‚
â”‚     â””â”€â”€ Kafka â†’ Bronze Layer (real-time, sub-second latency)             â”‚
â”‚                                                                           â”‚
â”‚   Spark Batch Jobs (Medallion Architecture)                              â”‚
â”‚     â”œâ”€â”€ Bronze â†’ Silver : Deduplication, null handling, type casting     â”‚
â”‚     â”œâ”€â”€ Silver â†’ Gold   : Aggregations, feature engineering, indexing    â”‚
â”‚     â””â”€â”€ Gold  â†’ BigQuery: Analytics-ready dimensional tables             â”‚
â”‚                                                                           â”‚
â”‚   Great Expectations â”€â”€ Data quality validation at every layer           â”‚
â”‚   Apache Airflow â”€â”€ DAG orchestration for all pipelines                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       STORAGE LAYER                                       â”‚
â”‚                                                                           â”‚
â”‚   Google Cloud Storage (Data Lake)                                       â”‚
â”‚     â”œâ”€â”€ gs://climate-bronze/  â†’ Raw Parquet (as received)                â”‚
â”‚     â”œâ”€â”€ gs://climate-silver/  â†’ Cleaned & validated                      â”‚
â”‚     â””â”€â”€ gs://climate-gold/    â†’ Feature-engineered & aggregated          â”‚
â”‚                                                                           â”‚
â”‚   Google BigQuery (Data Warehouse)                                       â”‚
â”‚     â”œâ”€â”€ Fact: fact_weather_readings, fact_predictions                    â”‚
â”‚     â”œâ”€â”€ Dim:  dim_location, dim_time, dim_weather_type                  â”‚
â”‚     â””â”€â”€ ML:   feature_store_weather                                      â”‚
â”‚                                                                           â”‚
â”‚   PostgreSQL (Application metadata & user state)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ML / AI LAYER                                      â”‚
â”‚                                                                           â”‚
â”‚   Traditional ML                                                         â”‚
â”‚     â”œâ”€â”€ XGBoost â”€â”€ Extreme weather classification                        â”‚
â”‚     â”œâ”€â”€ SHAP â”€â”€ Feature importance & explainability                      â”‚
â”‚     â””â”€â”€ Optuna â”€â”€ Hyperparameter optimization                            â”‚
â”‚                                                                           â”‚
â”‚   Deep Learning (PyTorch)                                                â”‚
â”‚     â”œâ”€â”€ LSTM â”€â”€ Time-series forecasting (temperature, pressure)          â”‚
â”‚     â”œâ”€â”€ GRU â”€â”€ Comparison variant                                        â”‚
â”‚     â””â”€â”€ Uncertainty quantification (confidence intervals)                â”‚
â”‚                                                                           â”‚
â”‚   Ensemble                                                               â”‚
â”‚     â””â”€â”€ Weighted voting: XGBoost + LSTM combined predictions             â”‚
â”‚                                                                           â”‚
â”‚   MLflow â”€â”€ Experiment tracking, model versioning, registry              â”‚
â”‚   Vertex AI â”€â”€ Production model serving (auto-scaling endpoints)         â”‚
â”‚   Evidently AI â”€â”€ Data drift & model performance monitoring              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      GEN AI LAYER                                         â”‚
â”‚                                                                           â”‚
â”‚   Natural Language Report Generator                                      â”‚
â”‚     â””â”€â”€ Raw predictions â†’ LLM â†’ Human-readable weather intelligence      â”‚
â”‚         Example: "Severe heatwave expected in Phoenix, AZ. Temperatures  â”‚
â”‚         will exceed 115Â°F over the next 72 hours. Risk level: HIGH."     â”‚
â”‚                                                                           â”‚
â”‚   Anomaly Explanation Engine                                             â”‚
â”‚     â””â”€â”€ Model detects anomaly â†’ LLM explains WHY in plain English        â”‚
â”‚                                                                           â”‚
â”‚   RAG-Powered Climate Chatbot                                            â”‚
â”‚     â””â”€â”€ User: "What caused the 2024 Texas floods?"                       â”‚
â”‚         â†’ Retrieves from ChromaDB â†’ LLM generates grounded answer        â”‚
â”‚                                                                           â”‚
â”‚   Text-to-SQL Query Engine                                               â”‚
â”‚     â””â”€â”€ User: "Show heatwave predictions for California next week"       â”‚
â”‚         â†’ Converts to SQL â†’ Queries BigQuery â†’ Returns natural response  â”‚
â”‚                                                                           â”‚
â”‚   ChromaDB (Vector Store) + Sentence-Transformers (Embeddings)           â”‚
â”‚   LangChain (Orchestration) + Gemini / Claude API (LLM)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SERVING & VISUALIZATION                                 â”‚
â”‚                                                                           â”‚
â”‚   FastAPI Backend                                                        â”‚
â”‚     â”œâ”€â”€ POST /predict       â†’ Weather predictions                        â”‚
â”‚     â”œâ”€â”€ POST /chat          â†’ Gen AI chatbot                             â”‚
â”‚     â”œâ”€â”€ GET  /anomalies     â†’ Anomaly explanations                       â”‚
â”‚     â”œâ”€â”€ GET  /reports       â†’ Generated weather reports                  â”‚
â”‚     â””â”€â”€ GET  /health        â†’ Service health check                       â”‚
â”‚                                                                           â”‚
â”‚   Streamlit Dashboard                                                    â”‚
â”‚     â”œâ”€â”€ Real-time weather map with prediction overlays                   â”‚
â”‚     â”œâ”€â”€ Historical trend analysis & model accuracy tracker               â”‚
â”‚     â”œâ”€â”€ Interactive chatbot tab (natural language queries)               â”‚
â”‚     â””â”€â”€ Model performance & drift monitoring panel                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DEPLOYMENT & INFRASTRUCTURE                              â”‚
â”‚                                                                           â”‚
â”‚   Docker â”€â”€ Every service containerized (12+ Dockerfiles)                â”‚
â”‚   Docker Compose â”€â”€ Local development (single command startup)           â”‚
â”‚   GKE (Kubernetes) â”€â”€ Production container orchestration                 â”‚
â”‚   Terraform â”€â”€ Infrastructure as Code (all GCP resources)                â”‚
â”‚   GitHub Actions â”€â”€ CI/CD (lint, test, build, deploy)                    â”‚
â”‚   Prometheus + Grafana â”€â”€ Infrastructure monitoring & alerting           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies | Purpose |
|----------|-------------|---------|
| **Data Ingestion** | Apache Kafka (3-broker), Schema Registry (Avro), Kafka Connect | Real-time streaming ingestion with data contracts |
| **Stream Processing** | Spark Structured Streaming | Sub-second processing from Kafka to data lake |
| **Batch Processing** | Apache Spark (PySpark), Spark SQL | Medallion transformations (Bronze â†’ Silver â†’ Gold) |
| **Orchestration** | Apache Airflow | DAG-based pipeline scheduling & dependency management |
| **Data Quality** | Great Expectations | Automated validation checkpoints at every layer |
| **Data Lake** | Google Cloud Storage (GCS) | Partitioned Parquet files in medallion layers |
| **Data Warehouse** | Google BigQuery | Star schema dimensional model for analytics |
| **Traditional ML** | XGBoost, Scikit-learn, SHAP, Optuna | Classification, explainability, hyperparameter tuning |
| **Deep Learning** | PyTorch (LSTM, GRU) | Time-series forecasting with uncertainty quantification |
| **ML Ops** | MLflow, Evidently AI | Experiment tracking, model registry, drift detection |
| **Model Serving** | Vertex AI Endpoints | Auto-scaling production inference |
| **Gen AI** | Gemini/Claude API, LangChain, ChromaDB | RAG chatbot, report generation, text-to-SQL |
| **Backend API** | FastAPI | High-performance async REST API |
| **Frontend** | Streamlit | Interactive dashboard with real-time visualizations |
| **Containerization** | Docker, Docker Compose | Service isolation & reproducible environments |
| **Cloud Platform** | GCP (GKE, GCS, BigQuery, Vertex AI, Cloud Run) | Production deployment |
| **Infrastructure as Code** | Terraform | Automated GCP resource provisioning |
| **CI/CD** | GitHub Actions | Automated testing, building, and deployment |
| **Monitoring** | Prometheus, Grafana | Infrastructure metrics & alerting |

---

## âœ¨ Features

### Data Engineering
- **Real-time ingestion** from 4+ weather data sources via Kafka
- **Schema enforcement** with Avro and Schema Registry (backward compatible evolution)
- **Medallion data lake** (Bronze â†’ Silver â†’ Gold) on GCS
- **Star schema** dimensional model in BigQuery
- **Automated data quality** checks with Great Expectations at every layer
- **Airflow DAGs** orchestrating ingestion, processing, training, and monitoring

### Machine Learning
- **Extreme weather classification** (flood, heatwave, storm, hurricane) with XGBoost
- **Time-series forecasting** (temperature, pressure, wind) with LSTM & GRU
- **Ensemble model** combining traditional ML + deep learning
- **Explainability** via SHAP values (know WHY the model predicted an event)
- **Uncertainty quantification** with confidence intervals on every prediction
- **Automated hyperparameter tuning** with Optuna
- **Full experiment tracking** with MLflow (metrics, parameters, artifacts)
- **Model drift detection** with Evidently AI

### Generative AI
- **Natural language weather reports** generated from raw model predictions
- **Anomaly explanation engine** â€” when models detect something unusual, the LLM explains why
- **RAG-powered chatbot** â€” ask climate questions grounded in your actual data
- **Text-to-SQL** â€” query BigQuery using natural language ("Show me all storms in Texas last month")

### Deployment & Operations
- **12+ Dockerized microservices** with Docker Compose for local development
- **Kubernetes (GKE)** manifests for production orchestration
- **Terraform** for all GCP infrastructure as code
- **GitHub Actions CI/CD** with automated lint, test, build, and deploy
- **Prometheus + Grafana** monitoring with custom dashboards

---

## ğŸ“ Project Structure

```
climate-intelligence-platform/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml                    # Start everything locally with one command
â”œâ”€â”€ .env.example                          # Environment variable template
â”œâ”€â”€ requirements.txt                      # Python dependencies
â”œâ”€â”€ Makefile                              # Common commands (make build, make test, etc.)
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                        # Lint + test on every pull request
â”‚       â””â”€â”€ cd.yml                        # Build + deploy on merge to main
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ main.tf                       # GCS, BigQuery, GKE, Vertex AI resources
â”‚   â”‚   â”œâ”€â”€ variables.tf                  # Configurable parameters
â”‚   â”‚   â””â”€â”€ outputs.tf                    # Resource IDs & endpoints
â”‚   â””â”€â”€ kubernetes/
â”‚       â”œâ”€â”€ kafka-deployment.yml
â”‚       â”œâ”€â”€ spark-deployment.yml
â”‚       â”œâ”€â”€ api-deployment.yml
â”‚       â”œâ”€â”€ dashboard-deployment.yml
â”‚       â””â”€â”€ monitoring-deployment.yml
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ kafka_producer_noaa.py            # NOAA API â†’ Kafka
â”‚   â”œâ”€â”€ kafka_producer_openweather.py     # OpenWeatherMap API â†’ Kafka
â”‚   â”œâ”€â”€ kafka_producer_nasa.py            # NASA satellite metadata â†’ Kafka
â”‚   â”œâ”€â”€ avro_schemas/
â”‚   â”‚   â”œâ”€â”€ weather_reading.avsc          # Schema for weather observations
â”‚   â”‚   â””â”€â”€ weather_alert.avsc           # Schema for severe weather alerts
â”‚   â””â”€â”€ kafka_connect/
â”‚       â””â”€â”€ gcs_sink_connector.json       # Auto-archive raw messages to GCS
â”‚
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ spark_streaming_bronze.py         # Kafka â†’ Bronze (real-time)
â”‚   â”œâ”€â”€ spark_batch_silver.py             # Bronze â†’ Silver (cleaning)
â”‚   â”œâ”€â”€ spark_batch_gold.py               # Silver â†’ Gold (feature engineering)
â”‚   â”œâ”€â”€ spark_to_bigquery.py              # Gold â†’ BigQuery (warehouse load)
â”‚   â””â”€â”€ data_quality/
â”‚       â””â”€â”€ great_expectations/
â”‚           â”œâ”€â”€ expectations/
â”‚           â”‚   â”œâ”€â”€ bronze_suite.json     # Raw data expectations
â”‚           â”‚   â”œâ”€â”€ silver_suite.json     # Cleaned data expectations
â”‚           â”‚   â””â”€â”€ gold_suite.json       # Feature data expectations
â”‚           â””â”€â”€ checkpoints/
â”‚               â””â”€â”€ weather_checkpoint.yml
â”‚
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ daily_ingestion_dag.py        # Scheduled data collection
â”‚       â”œâ”€â”€ batch_processing_dag.py       # Bronze â†’ Silver â†’ Gold â†’ BigQuery
â”‚       â”œâ”€â”€ model_training_dag.py         # Weekly retraining pipeline
â”‚       â””â”€â”€ model_monitoring_dag.py       # Daily drift detection
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ feature_engineering.py            # Create ML features from Gold data
â”‚   â”œâ”€â”€ train_xgboost.py                 # XGBoost classifier training
â”‚   â”œâ”€â”€ train_lstm.py                    # PyTorch LSTM training
â”‚   â”œâ”€â”€ train_gru.py                     # PyTorch GRU variant
â”‚   â”œâ”€â”€ ensemble_model.py               # Combine XGBoost + LSTM predictions
â”‚   â”œâ”€â”€ hyperparameter_tuning.py         # Optuna optimization
â”‚   â”œâ”€â”€ model_evaluation.py             # Metrics, SHAP, confusion matrix
â”‚   â””â”€â”€ mlflow_config.py                # MLflow tracking server config
â”‚
â”œâ”€â”€ genai/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ rag_pipeline.py                  # ChromaDB retrieval + LLM generation
â”‚   â”œâ”€â”€ report_generator.py             # Predictions â†’ natural language reports
â”‚   â”œâ”€â”€ anomaly_explainer.py            # Anomaly â†’ LLM explanation
â”‚   â”œâ”€â”€ text_to_sql.py                  # Natural language â†’ BigQuery SQL
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ embed_historical_reports.py  # Build vector store from climate docs
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ report_prompt.txt            # Prompt template for reports
â”‚       â”œâ”€â”€ anomaly_prompt.txt           # Prompt template for anomaly explanation
â”‚       â””â”€â”€ sql_prompt.txt               # Prompt template for text-to-SQL
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py                          # FastAPI application entry point
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ predictions.py               # /predict endpoints
â”‚   â”‚   â”œâ”€â”€ chat.py                      # /chat endpoints (Gen AI)
â”‚   â”‚   â”œâ”€â”€ anomalies.py                # /anomalies endpoints
â”‚   â”‚   â”œâ”€â”€ reports.py                  # /reports endpoints
â”‚   â”‚   â””â”€â”€ health.py                   # /health endpoint
â”‚   â””â”€â”€ schemas/
â”‚       â”œâ”€â”€ request_models.py            # Pydantic request schemas
â”‚       â””â”€â”€ response_models.py           # Pydantic response schemas
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app.py                           # Streamlit main entry point
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ 1_realtime_map.py           # Live weather map + predictions
â”‚   â”‚   â”œâ”€â”€ 2_historical_trends.py      # Trend analysis & charts
â”‚   â”‚   â”œâ”€â”€ 3_chatbot.py               # Gen AI chatbot interface
â”‚   â”‚   â””â”€â”€ 4_model_monitoring.py       # Drift & accuracy tracking
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ api_client.py               # Helper to call FastAPI backend
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus.yml              # Scrape configs for all services
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â”‚       â”œâ”€â”€ pipeline_health.json    # Data pipeline metrics
â”‚   â”‚       â””â”€â”€ model_performance.json  # ML model metrics
â”‚   â””â”€â”€ evidently/
â”‚       â””â”€â”€ drift_detection.py          # Scheduled drift reports
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ingestion/
â”‚   â”‚   â””â”€â”€ test_kafka_producer.py
â”‚   â”œâ”€â”€ test_processing/
â”‚   â”‚   â””â”€â”€ test_spark_jobs.py
â”‚   â”œâ”€â”€ test_ml/
â”‚   â”‚   â””â”€â”€ test_model_training.py
â”‚   â”œâ”€â”€ test_genai/
â”‚   â”‚   â””â”€â”€ test_rag_pipeline.py
â”‚   â””â”€â”€ test_api/
â”‚       â””â”€â”€ test_endpoints.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_local.sh                  # Install dependencies & start Docker
â”‚   â”œâ”€â”€ setup_gcp.sh                    # Create GCP project & enable APIs
â”‚   â”œâ”€â”€ create_kafka_topics.sh          # Initialize Kafka topics
â”‚   â””â”€â”€ load_historical_data.sh         # Backfill historical weather data
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ ARCHITECTURE.md                  # Detailed architecture decisions
    â”œâ”€â”€ DEPLOYMENT.md                    # Step-by-step cloud deployment guide
    â”œâ”€â”€ API.md                           # Full API reference
    â””â”€â”€ TROUBLESHOOTING.md              # Common issues & fixes
```

---

## ğŸš€ Getting Started

### Prerequisites

| Tool | Version | Installation |
|------|---------|-------------|
| Python | 3.10+ | [python.org](https://python.org) |
| Docker Desktop | Latest | [docker.com](https://docker.com/products/docker-desktop) |
| Git | Latest | [git-scm.com](https://git-scm.com) |
| Google Cloud SDK | Latest | [cloud.google.com/sdk](https://cloud.google.com/sdk/docs/install) |

### Quick Start (Local Development)

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/climate-intelligence-platform.git
cd climate-intelligence-platform

# 2. Copy environment template and add your API keys
cp .env.example .env
# Edit .env with your NOAA_API_KEY, OPENWEATHER_API_KEY, GEMINI_API_KEY

# 3. Start all services (Kafka, Spark, Airflow, API, Dashboard, etc.)
docker-compose up -d

# 4. Verify services are running
docker-compose ps
```

### Access Points (Local)

| Service | URL | Description |
|---------|-----|-------------|
| **FastAPI** | http://localhost:8000 | REST API + Swagger docs at /docs |
| **Streamlit Dashboard** | http://localhost:8501 | Interactive visualization |
| **Airflow** | http://localhost:8080 | Pipeline orchestration UI |
| **Spark Master** | http://localhost:8090 | Spark job monitoring |
| **MLflow** | http://localhost:5000 | Experiment tracking UI |
| **Kafka UI** | http://localhost:9021 | Kafka topic monitoring |
| **Grafana** | http://localhost:3000 | Infrastructure dashboards |
| **Prometheus** | http://localhost:9090 | Metrics collection |

---

## ğŸ”„ Pipeline Deep Dive

### 1. Ingestion (Kafka Producers)

Weather data flows from multiple APIs into a 3-broker Kafka cluster. Each source has its own producer with Avro schema validation via Schema Registry. This ensures data contracts are enforced before any data enters the pipeline.

```
NOAA API â”€â”€â”€â”€â”€â”
               â”œâ”€â”€â†’ Kafka Broker Cluster â”€â”€â†’ 3 Topics (partitioned by region)
OpenWeather â”€â”€â”¤                               â”‚
               â”‚                               â”œâ”€â”€â†’ Spark Streaming (real-time)
NASA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â†’ Kafka Connect â†’ GCS (archival)
```

### 2. Processing (Medallion Architecture)

| Layer | Purpose | Format | Example Transformation |
|-------|---------|--------|----------------------|
| **Bronze** | Raw data as-is | Parquet, partitioned by `ingestion_date` | Kafka JSON â†’ Parquet |
| **Silver** | Cleaned & validated | Parquet, partitioned by `date/region` | Remove nulls, fix types, deduplicate |
| **Gold** | Business-ready features | Parquet, partitioned by `date/region` | Rolling averages, heat index, anomaly flags |

### 3. Warehouse (BigQuery Star Schema)

```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  dim_time     â”‚
              â”‚  date_key     â”‚
              â”‚  hour, day    â”‚
              â”‚  month, year  â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ dim_location  â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤ fact_weather      â”‚
â”‚ location_key  â”‚     â”‚     â”‚ temperature       â”‚
â”‚ city, state   â”‚     â”‚     â”‚ humidity          â”‚
â”‚ lat, lon      â”‚     â”‚     â”‚ wind_speed        â”‚
â”‚ region        â”‚     â”‚     â”‚ pressure          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â”‚ precipitation     â”‚
                     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
              â”‚dim_weather   â”‚
              â”‚type          â”‚
              â”‚severity      â”‚
              â”‚category      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– ML Models

| Model | Task | Input | Output |
|-------|------|-------|--------|
| **XGBoost** | Classify extreme weather events | Gold layer features (30+ features) | Event type + probability |
| **LSTM** | Forecast temperature/pressure | 7-day sliding window time-series | 24-72 hour forecast + confidence interval |
| **GRU** | Benchmark comparison to LSTM | Same as LSTM | Same as LSTM |
| **Ensemble** | Final production prediction | XGBoost + LSTM outputs | Weighted combined prediction |

All experiments tracked in **MLflow** with metrics, parameters, and model artifacts. Best model auto-promoted to **Vertex AI** for serving.

---

## ğŸ§  Gen AI Integration

| Feature | How It Works | Example |
|---------|-------------|---------|
| **Weather Reports** | Model prediction â†’ LLM prompt â†’ Natural language report | *"A severe heatwave is expected in Phoenix, AZ over the next 72 hours with temperatures exceeding 115Â°F. Risk level: HIGH. Recommend increased water distribution and cooling center activation."* |
| **Anomaly Explainer** | Anomaly detected â†’ Historical context retrieved â†’ LLM explains | *"Unusual pressure drop detected in Gulf Coast region. Historically, this pattern preceded Category 3+ hurricanes 73% of the time."* |
| **RAG Chatbot** | Question â†’ Embed â†’ Retrieve from ChromaDB â†’ LLM answer | User: "What caused major flooding in Houston?" â†’ Grounded answer from historical data |
| **Text-to-SQL** | Natural language â†’ SQL query â†’ BigQuery â†’ Natural response | User: "How many storms hit Florida in 2024?" â†’ `SELECT COUNT(*)...` â†’ "There were 47 storm events recorded in Florida during 2024." |

---

## â˜ï¸ Deployment

### Local Development
```bash
docker-compose up -d        # Start all services
docker-compose logs -f      # View logs
docker-compose down         # Stop all services
```

### GCP Production Deployment
```bash
# 1. Set up GCP infrastructure with Terraform
cd infrastructure/terraform
terraform init
terraform plan
terraform apply

# 2. Build & push Docker images to Artifact Registry
bash scripts/build_and_push.sh

# 3. Deploy to GKE
kubectl apply -f infrastructure/kubernetes/

# 4. Verify deployment
kubectl get pods -n climate-platform
```

### CI/CD Pipeline (GitHub Actions)
```
Push to feature branch â†’ Lint & Test â†’ Build Docker images
                                              â”‚
Merge to main â†’ Build â†’ Push to Artifact Registry â†’ Deploy to GKE
```

---

## ğŸ“Š Monitoring

| Tool | What It Monitors |
|------|-----------------|
| **Prometheus** | Service uptime, API latency, Kafka lag, Spark job duration |
| **Grafana** | Visual dashboards for all metrics with alerting |
| **Evidently AI** | Data drift (input feature distribution changes), model performance drift (accuracy/F1 degradation) |
| **MLflow** | Experiment history, model versions, comparison across runs |
| **Airflow UI** | DAG run status, task failures, retry history |

---

## ğŸ“¡ API Documentation

Full interactive docs available at `http://localhost:8000/docs` (Swagger UI) when running locally.

### Key Endpoints

```
POST   /api/v1/predict          â†’ Get extreme weather prediction for a location
POST   /api/v1/chat             â†’ Ask a climate question (Gen AI chatbot)
GET    /api/v1/anomalies        â†’ List recent anomalies with LLM explanations
GET    /api/v1/reports/{date}   â†’ Get generated weather report for a date
GET    /api/v1/health           â†’ Service health check
```

### Example Request
```bash
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{
    "latitude": 33.4484,
    "longitude": -112.0740,
    "forecast_hours": 72
  }'
```

### Example Response
```json
{
  "location": "Phoenix, AZ",
  "predictions": [
    {
      "event_type": "heatwave",
      "probability": 0.89,
      "severity": "extreme",
      "confidence_interval": [0.82, 0.94],
      "forecast_window": "2025-07-15 to 2025-07-18",
      "explanation": "Persistent high-pressure ridge combined with record soil moisture deficit indicates extreme heat event."
    }
  ],
  "model_version": "ensemble-v2.3.1",
  "generated_report": "A severe heatwave is expected in Phoenix, AZ..."
}
```

---

## ğŸ“… Implementation Roadmap

| Week | Focus | Key Deliverables |
|------|-------|-----------------|
| **1** | Foundation & Kafka | Project setup, Docker Compose, Kafka cluster running, first message flowing |
| **2** | Data Ingestion | Python producers for NOAA + OpenWeather, Avro schemas, Kafka Connect to GCS |
| **3** | Spark Processing | Structured Streaming (Kafka â†’ Bronze), batch jobs (Silver, Gold), GCS partitioning |
| **4** | BigQuery & Airflow | Star schema design, Gold â†’ BigQuery load, Airflow DAGs, Great Expectations |
| **5** | ML Models & MLflow | XGBoost + LSTM training, ensemble, SHAP, Optuna, MLflow tracking |
| **6** | Gen AI Integration | ChromaDB + RAG, report generator, anomaly explainer, text-to-SQL |
| **7** | API & Dashboard | FastAPI endpoints, Streamlit dashboard, Evidently drift monitoring |
| **8** | Deployment & CI/CD | Dockerize all services, Terraform, GKE deploy, GitHub Actions, Grafana |

---

## ğŸ“ Why This Project Stands Out

- **End-to-end**: From raw API data to Gen AI-powered insights â€” not just a notebook
- **Production-grade**: Kafka, Docker, Kubernetes, CI/CD, monitoring â€” how real systems work
- **Modern stack**: Combines traditional big data (Spark) with cutting-edge Gen AI (RAG, LLMs)
- **Explainable AI**: SHAP values + LLM explanations â€” not a black box
- **Scalable**: Designed to handle terabytes with proper partitioning, streaming, and auto-scaling

---

## ğŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## ğŸ¤ Contributing

Contributions are welcome. Please read [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

---

*Built with â¤ï¸ for climate resilience*
